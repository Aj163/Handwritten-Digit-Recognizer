{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, InputLayer\n",
    "from keras.models import Sequential\n",
    "from keras import metrics\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import the dataset\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the train and test data\n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "test_data = mnist.test.images  # Returns np.array\n",
    "test_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "train_labels = train_labels.reshape(-1, 1)\n",
    "test_labels = test_labels.reshape(-1, 1)\n",
    "\n",
    "train_data = train_data.reshape((-1, 28, 28, 1))\n",
    "train_labels = train_labels\n",
    "test_data = test_data.reshape((-1, 28, 28, 1))\n",
    "test_labels = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Shapes\n",
      "Train Data: (55000, 28, 28, 1)\n",
      "Train Labels: (55000, 1)\n",
      "Test Data: (10000, 28, 28, 1)\n",
      "Test labels: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('>>> Shapes')\n",
    "print('Train Data:', train_data.shape)\n",
    "print('Train Labels:', train_labels.shape)\n",
    "print('Test Data:', test_data.shape)\n",
    "print('Test labels:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=1024, activation='relu'))\n",
    "model.add(Dropout(rate=0.4, noise_shape=None, seed=None))\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 154s 3ms/step - loss: 0.1291 - sparse_categorical_accuracy: 0.9590\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 152s 3ms/step - loss: 0.0420 - sparse_categorical_accuracy: 0.9871\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 152s 3ms/step - loss: 0.0293 - sparse_categorical_accuracy: 0.9907\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 146s 3ms/step - loss: 0.0222 - sparse_categorical_accuracy: 0.9929\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 150s 3ms/step - loss: 0.0173 - sparse_categorical_accuracy: 0.9944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff248352278>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_data, y=train_labels, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 38s 695us/step\n",
      "10000/10000 [==============================] - 7s 728us/step\n",
      "\n",
      "Train accuracy: 99.74\n",
      "Test accuracy: 99.13\n"
     ]
    }
   ],
   "source": [
    "_, accuracy_train = model.evaluate(train_data, train_labels)\n",
    "_, accuracy_test = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print('\\nTrain accuracy:', round(accuracy_train*100, 2))\n",
    "print('Test accuracy:', round(accuracy_test*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
